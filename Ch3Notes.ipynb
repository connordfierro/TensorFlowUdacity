{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch3Notes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtZhFfVIOWsjrphCPUWPvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/connordfierro/TensorFlowUdacity/blob/main/Ch3Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5kaye3P47mY"
      },
      "outputs": [],
      "source": [
        "#from ch3 of Deep Learning w/ Python (Francois Chollet)\n",
        "\n",
        "#4 parts of neural networks: \n",
        "#1. layers (many layers make a model/network)\n",
        "#2. Input Data and Targets (to train the network)\n",
        "#3. Loss function (which creates feedback for learning)[Loss val]\n",
        "#4. Optimizer (determines how learning proceeds/optimizes fxn)\n",
        "\n",
        "#Tensors trained with Stochastic Gradient Descent contain Network Knowledge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P0-t4MP1FTRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RGvOaX97Cdmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#celcius to farenheit essential code: \n",
        "l0 = tf.keras.layers.Dense(units=1, input_shape=[1]) \n",
        "model = tf.keras.Sequential([l0])\n",
        "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))\n",
        "history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)\n",
        "model.predict([100.0])\n",
        "#common activation functions include ReLU, Sigmoid, tanh, ELU"
      ],
      "metadata": {
        "id": "lxVZOGPFxK5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "layer = layers.Dense(32, input_shape=(784,))\n",
        "#A dense layer with 32 output units\n",
        "\n",
        "model = models.Sequential()\n",
        "        model.add(layers.Dense(32, input_shape=(784,)))\n",
        "        model.add(layers.Dense(32)) #input automatically inferred from first layer"
      ],
      "metadata": {
        "id": "j2pXfDaJ6GTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A Deep-Learning model is a directed, acyclic graph of layers\n",
        "#Linear Layer Stacking is most common model(surjective)\n",
        "#Other network topologies include: Two-branch, Multihead, Inception\n",
        "\n",
        "#you’ll use binary crossentropy for a two-class classification problem, \n",
        "#categorical crossentropy for a many-class classification problem, \n",
        "#mean- squared error for a regression problem, \n",
        "#connectionist temporal classification (CTC) for a sequence-learning problem,etc. "
      ],
      "metadata": {
        "id": "BH8Z-Nr-7ccj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.2.1:\n",
        "#Keras Backend support includes TensorFlow, Theano, & Microsoft Cognitive Toolkit (CNTK)\n",
        " # + more now??\n",
        "#When running on CPU, TensorFlow is itself wrapping a low-level library for tensor operations\n",
        "#called Eigen (http://eigen.tuxfamily.org). On GPU, TensorFlow wraps a library of\n",
        "#well-optimized deep-learning operations called the NVIDIA CUDA Deep Neural Network library (cuDNN).\n"
      ],
      "metadata": {
        "id": "JolbFGuTCekH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.2.2\n",
        "#Keras Workflow:\n",
        "#1. Define Training data (input tensors/target tensors)\n",
        "#2. Define Network Layers (model) that maps input to target\n",
        "#3. Configure learning process w/ loss function, optimizer, & metrics\n",
        "#4. Iterate training data by calling fit() method of model\n",
        "\n",
        "#Models can be defined with Sequential (for linear layers) or functional api (DAGs)\n",
        "#Example:\n",
        "from keras import models\n",
        "from keras import layers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "#And here’s the same model defined using the functional API:\n",
        "input_tensor = layers.Input(shape=(784,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
        "model = models.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "#Here’s an example with a single loss function, which is by far the most common case:\n",
        "from keras import optimizers\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)\n",
        "#See Appendix B for AWS EC2 setup (instead of jupyter)\n"
      ],
      "metadata": {
        "id": "1Nt5UWMCDRVb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}