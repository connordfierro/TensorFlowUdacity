{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuClassiEx.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdc6uh3q8k0I3lJnr0BS0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/connordfierro/TensorFlowUdacity-Quantum-txtbook/blob/main/QuClassiEx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4ijAKUDdc3c"
      },
      "outputs": [],
      "source": [
        "#copy/pasted directly from Samuelstein1224 github QuClassiExample page\n",
        "\n",
        "#from Ying Mao's 2022 Summer Research into Deep Learning with Quantum Computing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------- ----------------------- -----------------------\n",
        "# This is the following code to the ML Sys Q\n",
        "# -----------------------------------------------------------------------\n",
        "!pip install qiskit\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from qiskit import QuantumRegister, ClassicalRegister\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit import Aer, execute\n",
        "from math import pi,log\n",
        "from qiskit import *\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from qiskit import Aer, IBMQ\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnytzBDjdxz_",
        "outputId": "ebd6fb4e-fee5-45ab-b80c-815143f46850"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-0.36.2.tar.gz (13 kB)\n",
            "Collecting qiskit-terra==0.20.2\n",
            "  Downloading qiskit_terra-0.20.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 5.9 MB/s \n",
            "\u001b[?25hCollecting qiskit-aer==0.10.4\n",
            "  Downloading qiskit_aer-0.10.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (18.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.0 MB 33.7 MB/s \n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.19.1\n",
            "  Downloading qiskit_ibmq_provider-0.19.1-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 64.9 MB/s \n",
            "\u001b[?25hCollecting qiskit-ignis==0.7.1\n",
            "  Downloading qiskit_ignis-0.7.1-py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 75.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.10.4->qiskit) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.10.4->qiskit) (1.21.6)\n",
            "Collecting requests-ntlm>=1.1.0\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.1->qiskit) (2.23.0)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting websocket-client>=1.0.1\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting retworkx>=0.8.0\n",
            "  Downloading retworkx-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ignis==0.7.1->qiskit) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.20.2->qiskit) (5.4.8)\n",
            "Collecting python-constraint>=1.4\n",
            "  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n",
            "Collecting tweedledum<2.0,>=1.1\n",
            "  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)\n",
            "\u001b[K     |████████████████████████████████| 943 kB 55.6 MB/s \n",
            "\u001b[?25hCollecting stevedore>=3.0.0\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting scipy>=1.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting ply>=3.10\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.20.2->qiskit) (1.7.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.20.2->qiskit) (0.3.5.1)\n",
            "Collecting symengine>=0.9\n",
            "  Downloading symengine-0.9.2-cp37-cp37m-manylinux2010_x86_64.whl (37.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.5 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.19.1->qiskit) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.1->qiskit) (2022.6.15)\n",
            "Collecting cryptography>=1.3\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 52.8 MB/s \n",
            "\u001b[?25hCollecting ntlm-auth>=1.0.2\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.1->qiskit) (2.21)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra==0.20.2->qiskit) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.20.2->qiskit) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.20.2->qiskit) (4.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-terra==0.20.2->qiskit) (1.2.1)\n",
            "Building wheels for collected packages: qiskit, python-constraint\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.36.2-py3-none-any.whl size=11933 sha256=b151788924711c940d894816735c4aa9a924a2fdcfb11566f16fe17107070282\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/f7/83/e2755ad17aa35bc145fce34e184aaf394a265a978d95caaabf\n",
            "  Building wheel for python-constraint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24081 sha256=f6212eea41e6afa164643d93de3162c2134d1c1119016adc8e24844990f529ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/27/db/1222c80eb1e431f3d2199c12569cb1cac60f562a451fe30479\n",
            "Successfully built qiskit python-constraint\n",
            "Installing collected packages: pbr, tweedledum, symengine, stevedore, scipy, retworkx, python-constraint, ply, ntlm-auth, cryptography, websockets, websocket-client, requests-ntlm, qiskit-terra, qiskit-ignis, qiskit-ibmq-provider, qiskit-aer, qiskit\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed cryptography-37.0.2 ntlm-auth-1.5.0 pbr-5.9.0 ply-3.11 python-constraint-1.4.0 qiskit-0.36.2 qiskit-aer-0.10.4 qiskit-ibmq-provider-0.19.1 qiskit-ignis-0.7.1 qiskit-terra-0.20.2 requests-ntlm-1.1.0 retworkx-0.11.0 scipy-1.7.3 stevedore-3.5.0 symengine-0.9.2 tweedledum-1.1.1 websocket-client-1.3.3 websockets-10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Network saving and loading\n",
        "epoch = 25 #train-iter in code below\n",
        "runtime_name = datetime.now().strftime(\"Date-%d%m%y--Hours-%H%M\")\n",
        "runtime_name += \"-epoch-{}\".format(epoch)\n",
        "os.mkdir(runtime_name)\n",
        "backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "# Subsample to SUBSAMPLE datapoints. This is due to computational cost.\n",
        "# Chance SUBSAMPLE to what best suits your computer, to make a reasonable training time.\n",
        "test_images,test_labels = tf.keras.datasets.mnist.load_data()\n",
        "train_images = test_images[0].reshape(60000,784)\n",
        "train_labels = test_images[1]\n",
        "labels = test_images[1]\n",
        "train_images = train_images/255\n",
        "k=4\n",
        "pca = PCA(n_components=k)\n",
        "pca.fit(train_images)\n",
        "# Computational cost is high for 60,000 data points. Change 6000 to what your system can handle\n",
        "SUBSAMPLE = 1000 #change this for faster processing(?)\n",
        "pca_data = pca.transform(train_images)[:SUBSAMPLE]\n",
        "train_labels = train_labels[:SUBSAMPLE]\n",
        "t_pca_data = pca_data.copy()\n",
        "pca_descaler = [[] for _ in range(k)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzuBPcbjd6TN",
        "outputId": "a76e5fc0-4937-49a3-ea4c-9a69753b3d8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data Transformation Section\n",
        "for i in range(k):\n",
        "    if pca_data[:,i].min() < 0:\n",
        "        pca_descaler[i].append(pca_data[:,i].min())\n",
        "        pca_data[:,i] += np.abs(pca_data[:,i].min())\n",
        "    else:\n",
        "        pca_descaler[i].append(pca_data[:,i].min())\n",
        "        pca_data[:,i] -= pca_data[:,i].min()\n",
        "    pca_descaler[i].append(pca_data[:,i].max())\n",
        "    pca_data[:,i] /= pca_data[:,i].max()\n",
        "pca_data_rot= 2*np.arcsin(np.sqrt(pca_data))\n",
        "valid_labels = None\n",
        "valid_labels = train_labels==3\n",
        "valid_labels += train_labels == 6\n",
        "\n",
        "for col in range(pca_data.shape[1]):\n",
        "    t_data_mean = pca_data[:,col].mean()\n",
        "    t_data_std = pca_data[:,col].std()\n",
        "    valid_upper_bound = pca_data[:,col] < t_data_mean+t_data_std\n",
        "    valid_lower_bound = pca_data[:,col] > t_data_mean-t_data_std\n",
        "    valid = np.logical_and(valid_upper_bound,valid_lower_bound)\n",
        "    pca_data = pca_data[valid]\n",
        "pca_data_rot3 = pca_data_rot[train_labels==3]\n",
        "pca_data_rot6 = pca_data_rot[train_labels==6]\n",
        "\n"
      ],
      "metadata": {
        "id": "MyYzHCDad_lV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpointing code\n",
        "def save_variables(var_dict, epoch, number_class):\n",
        "    with open(f\"{runtime_name}/Epoch-{epoch}-Variables-numbers-{number_class}\", 'w') as file:\n",
        "        file.write(str(var_dict))\n",
        "\n",
        "\n",
        "\n",
        "# Ran_ang returns a random angle\n",
        "def ran_ang():\n",
        "    return np.random.rand() * 2 * np.pi\n",
        "\n"
      ],
      "metadata": {
        "id": "Xe_GQOaYeDiM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def single_qubit_unitary(circ_ident, qubit_index, values):\n",
        "    circ_ident.ry(values[0], qubit_index)\n",
        "    circ_ident.rz(values[1], qubit_index)\n",
        "\n",
        "\n",
        "def dual_qubit_unitary(circ_ident, qubit_1, qubit_2, values):\n",
        "    circ_ident.ryy(values[0], qubit_1, qubit_2)\n",
        "    circ_ident.rzz(values[1], qubit_1, qubit_2)\n",
        "\n",
        "\n",
        "def controlled_dual_qubit_unitary(circ_ident, control_qubit, act_qubit, values):\n",
        "    circ_ident.cry(values[0], control_qubit, act_qubit)\n",
        "    circ_ident.crz(values[1], control_qubit, act_qubit)\n",
        "\n"
      ],
      "metadata": {
        "id": "q-Xyyp0ieDt5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def traditional_learning_layer(circ_ident, num_qubits, values, style=\"Dual\", qubit_start=1, qubit_end=5):\n",
        "    if style == \"Dual\":\n",
        "        for qub in np.arange(qubit_start, qubit_end):\n",
        "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
        "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
        "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
        "    elif style == \"Single\":\n",
        "        for qub in np.arange(qubit_start, qubit_end):\n",
        "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
        "    elif style == \"Controlled-Dual\":\n",
        "        for qub in np.arange(qubit_start, qubit_end):\n",
        "            single_qubit_unitary(circ_ident, qub, values[str(qub)])\n",
        "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
        "            dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \",\" + str(qub + 1)])\n",
        "        for qub in np.arange(qubit_start, qubit_end - 1):\n",
        "            controlled_dual_qubit_unitary(circ_ident, qub, qub + 1, values[str(qub) + \"--\" + str(qub + 1)])\n"
      ],
      "metadata": {
        "id": "nrvFuSjeeDxi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loading_circuit(circ_ident, num_qubits, values, qubit_start=1, qubit_end=5):\n",
        "    k = 0\n",
        "    for qub in np.arange(qubit_start, qubit_end):\n",
        "        circ_ident.ry(values[k], qub)\n",
        "        try:\n",
        "            circ_ident.rz(values[k + 1], qub)\n",
        "        except:\n",
        "            circ_ident.rz(0, qub)\n",
        "        k += 2\n",
        "\n",
        "\n",
        "def swap_test(circ_ident, num_qubits):\n",
        "    num_swap = num_qubits // 2\n",
        "    for i in range(num_swap):\n",
        "        circ_ident.cswap(0, i + 1, i + num_swap + 1)\n",
        "    circ_ident.h(0)\n",
        "    circ_ident.measure(0, 0)\n"
      ],
      "metadata": {
        "id": "g9t06S-beOxa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_random_variables(q, style):\n",
        "    trainable_variables = {}\n",
        "    if style == \"Single\":\n",
        "        for i in np.arange(1, q + 1):\n",
        "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
        "    elif style == \"Dual\":\n",
        "        for i in np.arange(1, q + 1):\n",
        "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
        "            if i != q:\n",
        "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
        "    elif style == \"Controlled-Dual\":\n",
        "        for i in np.arange(1, q + 1):\n",
        "            trainable_variables[str(i)] = [ran_ang(), ran_ang()]\n",
        "            if i != q:\n",
        "                trainable_variables[str(i) + \",\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
        "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [ran_ang(), ran_ang()]\n",
        "    return trainable_variables\n",
        "\n",
        "\n",
        "def init_gradient_variables(q, style):\n",
        "    trainable_variables = {}\n",
        "    if style == \"Single\":\n",
        "        for i in np.arange(1, q + 1):\n",
        "            trainable_variables[str(i)] = [[], []]\n",
        "    elif style == \"Dual\":\n",
        "        for i in np.arange(1, q + 1):\n",
        "            trainable_variables[str(i)] = [[], []]\n",
        "            if i != q:\n",
        "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
        "    elif style == \"Controlled-Dual\":\n",
        "        for i in np.arange(1, q + 1):\n",
        "            trainable_variables[str(i)] = [0, 0]\n",
        "            if i != q:\n",
        "                trainable_variables[str(i) + \",\" + str(i + 1)] = [[], []]\n",
        "                trainable_variables[str(i) + \"--\" + str(i + 1)] = [[], []]\n",
        "    return trainable_variables\n",
        "\n",
        "\n",
        "def get_probabilities(circ, count=10000, inducing=False):\n",
        "    if inducing == True:\n",
        "        count *= 10\n",
        "    job = execute(circ, backend, shots=count)\n",
        "    results = job.result().get_counts(circ)\n",
        "    try:\n",
        "        prob = results['0'] / (results['1'] + results['0'])\n",
        "        prob = (prob - 0.5)\n",
        "        if prob <= 0:\n",
        "            prob = 1e-16\n",
        "        else:\n",
        "            prob = prob * 2\n",
        "    except:\n",
        "        prob = 1\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "7GYMeGkNeOzj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------------\n",
        "# We treat the first n qubits are the discriminators state. n is always defined as the\n",
        "# integer division floor of the qubit count.\n",
        "# This is due to the fact that a state will always be k qubits, therefore the\n",
        "# number of total qubits must be 2k+1. 2k as we need k for the disc, and k to represent\n",
        "# either the other learned quantum state, or k to represent a data point\n",
        "# then +1 to perform the SWAP test. Therefore, we know that we will always end up\n",
        "# with an odd number of qubits. We take the floor to solve for k. 1st k represents\n",
        "# disc, 2nd k represents the \"loaded\" state be it gen or real data\n",
        "# ------------------------------------------------------------------------------------\n",
        "# Use different function calls to represent training a GENERATOR or training a DISCRIMINATOR\n",
        "# ------------------------------------------------------------------------------------\n",
        "def disc_real_training_circuit(training_variables, data, key=None, key_value=None, diff=False, fwd_diff=False):\n",
        "    circ = QuantumCircuit(q, c)\n",
        "    circ.h(0)\n",
        "    if diff == True and fwd_diff == True:\n",
        "        training_variables[key][key_value] += par_shift\n",
        "    if diff == True and fwd_diff == False:\n",
        "        training_variables[key][key_value] -= par_shift\n",
        "    traditional_learning_layer(circ, q, training_variables, style=layer_style, qubit_start=1, qubit_end=q // 2 + 1)\n",
        "    data_loading_circuit(circ, q, data, qubit_start=q // 2 + 1, qubit_end=q)\n",
        "    swap_test(circ, q)\n",
        "    if diff == True and fwd_diff == True:\n",
        "        training_variables[key][key_value] -= par_shift\n",
        "    if diff == True and fwd_diff == False:\n",
        "        training_variables[key][key_value] += par_shift\n",
        "    return circ\n"
      ],
      "metadata": {
        "id": "2fv_pbSoeO14"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function. SWAP Test returns probability, so minmax probability is logical\n",
        "def cost_function(p, yreal):\n",
        "    if yreal == 1:\n",
        "        return -np.log(p)\n",
        "    else:\n",
        "        return -np.log(1 - p)\n",
        "\n",
        "\n",
        "def update_weights(init_value, lr, grad):\n",
        "    while lr * grad > 2 * np.pi:\n",
        "        lr /= 10\n",
        "        print(\"Warning - Gradient taking steps that are very large. Drop learning rate\")\n",
        "    weight_update = lr * grad\n",
        "    new_value = init_value\n",
        "    if new_value - weight_update > 2 * np.pi:\n",
        "        new_value = (new_value - weight_update) - 2 * np.pi\n",
        "    elif new_value - weight_update < 0:\n",
        "        new_value = (new_value - weight_update) + 2 * np.pi\n",
        "    else:\n",
        "        new_value = new_value - weight_update\n",
        "    return new_value\n"
      ],
      "metadata": {
        "id": "hS83FY_YeO3u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------------------\n",
        "# THIS SECTION WE DO THE TUNING FOR WHAT WE KNOW WE WANT TO BE CHANGING!\n",
        "# ------------------------------------------------------------------------------------------\n",
        "\n",
        "q = 5  # Number of qubits = Dimensionality of data = round up to even number = num qubits\n",
        "c = 1\n",
        "circ = QuantumCircuit(q, c)\n",
        "circ.h(0)\n",
        "layer_style = \"Dual\" #Try Single/Controlled-Dual\n",
        "train_var_0 = init_random_variables(q // 2, layer_style)\n",
        "train_var_1 = init_random_variables(q // 2, layer_style)\n",
        "train_var_2 = init_random_variables(q // 2, layer_style)\n",
        "\n",
        "tracked_d_loss = []\n",
        "tracked_d_loss1 = []\n",
        "tracked_d_loss2 = []\n",
        "gradients = []\n",
        "learning_rate = 0.01\n",
        "train_iter = 25 #change this to change # epochs\n",
        "corr = 0\n",
        "wrong = 0\n",
        "loss_d_to_real = 0\n",
        "#First Training(train var0)\n",
        "print('Starting Training')\n",
        "print('-' * 20)\n",
        "print(\"train_var_0 training\")\n",
        "for epoch in range(train_iter):\n",
        "    start = time.time()\n",
        "    loss = [0, 0]\n",
        "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
        "    for index, point in enumerate(pca_data_rot3):\n",
        "        for key, value in train_var_0.items():\n",
        "            if str(q // 2 + 1) in key:\n",
        "                break\n",
        "            for key_value in range(len(value)):\n",
        "                forward_diff = -np.log(get_probabilities(\n",
        "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=True)))\n",
        "                backward_diff = -np.log(get_probabilities(\n",
        "                    disc_real_training_circuit(train_var_0, point, key, key_value, diff=True, fwd_diff=False)))\n",
        "                df = 0.5 * (forward_diff - backward_diff)\n",
        "                train_var_0[key][key_value] -= df * learning_rate\n",
        "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
        "    print(\"-\" * 20)\n",
        "    save_variables(train_var_0, epoch, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAXKaJ99ei-W",
        "outputId": "73cf3ebc-91e8-43ae-ee0e-f9bb1e421a90"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training\n",
            "--------------------\n",
            "train_var_0 training\n",
            "Time for Epoch 1 is 44.86542725563049 sec\n",
            "--------------------\n",
            "Time for Epoch 2 is 41.62569308280945 sec\n",
            "--------------------\n",
            "Time for Epoch 3 is 41.687336683273315 sec\n",
            "--------------------\n",
            "Time for Epoch 4 is 41.401607513427734 sec\n",
            "--------------------\n",
            "Time for Epoch 5 is 41.5396409034729 sec\n",
            "--------------------\n",
            "Time for Epoch 6 is 41.25858807563782 sec\n",
            "--------------------\n",
            "Time for Epoch 7 is 41.48114991188049 sec\n",
            "--------------------\n",
            "Time for Epoch 8 is 40.99747133255005 sec\n",
            "--------------------\n",
            "Time for Epoch 9 is 41.18739891052246 sec\n",
            "--------------------\n",
            "Time for Epoch 10 is 41.71356511116028 sec\n",
            "--------------------\n",
            "Time for Epoch 11 is 41.93289589881897 sec\n",
            "--------------------\n",
            "Time for Epoch 12 is 41.56021857261658 sec\n",
            "--------------------\n",
            "Time for Epoch 13 is 41.52140498161316 sec\n",
            "--------------------\n",
            "Time for Epoch 14 is 40.911540508270264 sec\n",
            "--------------------\n",
            "Time for Epoch 15 is 47.68190884590149 sec\n",
            "--------------------\n",
            "Time for Epoch 16 is 41.54392194747925 sec\n",
            "--------------------\n",
            "Time for Epoch 17 is 41.30926823616028 sec\n",
            "--------------------\n",
            "Time for Epoch 18 is 41.200175285339355 sec\n",
            "--------------------\n",
            "Time for Epoch 19 is 40.86203742027283 sec\n",
            "--------------------\n",
            "Time for Epoch 20 is 41.06655216217041 sec\n",
            "--------------------\n",
            "Time for Epoch 21 is 41.069744348526 sec\n",
            "--------------------\n",
            "Time for Epoch 22 is 41.295697927474976 sec\n",
            "--------------------\n",
            "Time for Epoch 23 is 41.42207050323486 sec\n",
            "--------------------\n",
            "Time for Epoch 24 is 40.50747323036194 sec\n",
            "--------------------\n",
            "Time for Epoch 25 is 42.44551086425781 sec\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Second Training(train var1)\n",
        "for epoch in range(train_iter):\n",
        "    start = time.time()\n",
        "    loss = [0, 0]\n",
        "    par_shift = 0.5 * np.pi / ((1 + epoch) ** 0.5)\n",
        "    for index, point in enumerate(pca_data_rot6):\n",
        "        for key, value in train_var_1.items():\n",
        "            if str(q // 2 + 1) in key:\n",
        "                break\n",
        "            for key_value in range(len(value)):\n",
        "                forward_diff = -np.log(get_probabilities(\n",
        "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=True)))\n",
        "                backward_diff = -np.log(get_probabilities(\n",
        "                    disc_real_training_circuit(train_var_1, point, key, key_value, diff=True, fwd_diff=False)))\n",
        "                df = 0.5 * (forward_diff - backward_diff)\n",
        "                train_var_1[key][key_value] -= df * learning_rate\n",
        "    print('Time for Epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
        "    print(\"-\" * 20)\n",
        "    save_variables(train_var_1, epoch, 6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seVn0V_uejAg",
        "outputId": "0b252a5f-2b98-4541-a516-370e91eba818"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for Epoch 1 is 43.00611329078674 sec\n",
            "--------------------\n",
            "Time for Epoch 2 is 42.28385543823242 sec\n",
            "--------------------\n",
            "Time for Epoch 3 is 41.70919489860535 sec\n",
            "--------------------\n",
            "Time for Epoch 4 is 41.93851280212402 sec\n",
            "--------------------\n",
            "Time for Epoch 5 is 41.648006200790405 sec\n",
            "--------------------\n",
            "Time for Epoch 6 is 41.68755507469177 sec\n",
            "--------------------\n",
            "Time for Epoch 7 is 41.68230175971985 sec\n",
            "--------------------\n",
            "Time for Epoch 8 is 41.687639474868774 sec\n",
            "--------------------\n",
            "Time for Epoch 9 is 47.564064264297485 sec\n",
            "--------------------\n",
            "Time for Epoch 10 is 46.49623203277588 sec\n",
            "--------------------\n",
            "Time for Epoch 11 is 43.78165817260742 sec\n",
            "--------------------\n",
            "Time for Epoch 12 is 41.45889449119568 sec\n",
            "--------------------\n",
            "Time for Epoch 13 is 41.69829082489014 sec\n",
            "--------------------\n",
            "Time for Epoch 14 is 41.64227795600891 sec\n",
            "--------------------\n",
            "Time for Epoch 15 is 41.59761357307434 sec\n",
            "--------------------\n",
            "Time for Epoch 16 is 42.101526498794556 sec\n",
            "--------------------\n",
            "Time for Epoch 17 is 41.66661262512207 sec\n",
            "--------------------\n",
            "Time for Epoch 18 is 41.8032603263855 sec\n",
            "--------------------\n",
            "Time for Epoch 19 is 41.63374471664429 sec\n",
            "--------------------\n",
            "Time for Epoch 20 is 41.64229869842529 sec\n",
            "--------------------\n",
            "Time for Epoch 21 is 41.51863503456116 sec\n",
            "--------------------\n",
            "Time for Epoch 22 is 41.88612151145935 sec\n",
            "--------------------\n",
            "Time for Epoch 23 is 41.65624928474426 sec\n",
            "--------------------\n",
            "Time for Epoch 24 is 41.9964919090271 sec\n",
            "--------------------\n",
            "Time for Epoch 25 is 41.47475576400757 sec\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CHANGE PCA_DATA_ROT VARS HERE\n",
        "pca_data = []\n",
        "[pca_data.append(x) for x in pca_data_rot3]\n",
        "[pca_data.append(x) for x in pca_data_rot6]\n",
        "labels = []\n",
        "[labels.append(0) for _ in range(len(pca_data_rot3))]\n",
        "[labels.append(1) for _ in range(len(pca_data_rot6))]\n",
        "#assess model accuracy\n",
        "correct = 0\n",
        "wrong = 0\n",
        "ones = []\n",
        "zeros = []\n",
        "layer_style = 'Dual'\n",
        "for index, x in enumerate(pca_data):\n",
        "    p0 = get_probabilities(disc_real_training_circuit(train_var_0, x, None, None, diff=False, fwd_diff=False))\n",
        "    p1 = get_probabilities(disc_real_training_circuit(train_var_1, x, None, None, diff=False, fwd_diff=False))\n",
        "    tp = p0 + p1\n",
        "    p0 = p0 / tp\n",
        "    p1 = p1 / tp\n",
        "    probs = np.array([p0, p1])\n",
        "    if np.argmax(probs) == labels[index]:\n",
        "        correct += 1\n",
        "    else:\n",
        "        wrong += 1\n",
        "\n",
        "print(f\"Accuracy {correct / (correct + wrong)}\")"
      ],
      "metadata": {
        "id": "jg8YQqi4ewQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28c6b72-a7f6-4577-d10e-3fdbdb7caade"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.7540106951871658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Results:\n",
        "#25 Epochs, 1000 subsample size, Dual run: Accuracy 0.7540106951871658"
      ],
      "metadata": {
        "id": "Bl_J9tztFg31"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}